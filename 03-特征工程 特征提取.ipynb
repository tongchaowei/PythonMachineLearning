{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征工程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对特征值的数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征抽取(提取)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将任意数据（如文本或图像）转换为可用于机器学习的数字特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征提取API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "sklearn.feature_extraction\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 字典特征提取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对字典数据进行特征值化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "应用场景：\n",
    "1. 数据集当中类别特征多(gender等)\n",
    "2. 数据类型为字典类型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "sklearn.feature_extraction.DictVectorizer(sparse=True) # 实例化一个转换器类的实例\n",
    "# Vector 向量\n",
    "# sparse=True 返回sparse矩阵\n",
    "# sparse=False 返回二维数组\n",
    "\n",
    "# 实例化对象调用：\n",
    "DictVectorizer.fit_transform(X) # X:字典或者包含字典的迭代器  返回值：返回sparse矩阵\n",
    "# 一个键有几种值，该特征对应的就有几列\n",
    "# sparse矩阵中有 toarray() 方法将sparse转为数组\n",
    "\n",
    "DictVectorizer.inverse_transform(X) # X:array数组或者sparse矩阵  返回值:转换之前数据格式\n",
    "DictVectorizer.get_feature_names() # 返回类别名称\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1.0\n",
      "  (0, 3)\t100.0\n",
      "  (1, 0)\t1.0\n",
      "  (1, 3)\t60.0\n",
      "  (2, 2)\t1.0\n",
      "  (2, 3)\t30.0\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "  {'city': '北京','temperature':100},\n",
    "  {'city': '上海','temperature':60},\n",
    "  {'city': '深圳','temperature':30}\n",
    "]\n",
    "transfer = DictVectorizer()\n",
    "\n",
    "data_new1 = transfer.fit_transform(data)\n",
    "# data_new1\n",
    "print(data_new1)\n",
    "# 使用稀疏矩阵节省内存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   1.,   0., 100.],\n",
       "       [  1.,   0.,   0.,  60.],\n",
       "       [  0.,   0.,   1.,  30.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transfer = DictVectorizer(sparse=False)\n",
    "data_new2 = transfer.fit_transform(data)\n",
    "data_new2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python3.10.0\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['city=上海', 'city=北京', 'city=深圳', 'temperature']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = transfer.get_feature_names()\n",
    "names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文本特征抽取 CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对文本数据进行特征值化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "sklearn.feature_extraction.text.CountVectorizer(stop_words=[])\n",
    "# 返回词频矩阵\n",
    "# stop_words 停用词，不进行统计的词\n",
    "\n",
    "CountVectorizer.fit_transform(X) # X:文本或者包含文本字符串的可迭代对象 返回值：返回sparse矩阵\n",
    "# 标点符号 单个字母不进行统计\n",
    "# 返回的矩阵中每行为每个字符串中单词出现的次数，没有出现为0\n",
    "\n",
    "CountVectorizer.inverse_transform(X) # X:array数组或者sparse矩阵 返回值:转换之前数据格\n",
    "CountVectorizer.get_feature_names() # 返回值:单词列表\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cw\\AppData\\Local\\Temp\\ipykernel_9452\\1790867367.py:1: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  import imp\n"
     ]
    }
   ],
   "source": [
    "import imp\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 3)\t2\n",
      "  (0, 5)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 5)\t1\n",
      "  (1, 7)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 0)\t1\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "  \"life is short,i like like python\",\n",
    "  \"life is too long,i dislike python\"\n",
    "]\n",
    "transfer = CountVectorizer()\n",
    "data_new1 = transfer.fit_transform(data)\n",
    "# data_new1\n",
    "print(data_new1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 2, 0, 1, 1, 0],\n",
       "       [1, 1, 1, 0, 1, 1, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new2 = data_new1.toarray()\n",
    "data_new2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dislike', 'is', 'life', 'like', 'long', 'python', 'short', 'too']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transfer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 停用词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 1 1 0]\n",
      " [1 1 1 1 0 1]] ['dislike', 'life', 'long', 'python', 'short', 'too']\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "  \"life is short,i like like python\",\n",
    "  \"life is too long,i dislike python\"\n",
    "]\n",
    "transfer = CountVectorizer(stop_words=['is', 'like'])\n",
    "data_new1 = transfer.fit_transform(data)\n",
    "# data_new1\n",
    "print(data_new1.toarray(), transfer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 中文文本特征抽取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [\n",
    "  \"你好你好你好啊\",\n",
    "  \"你也好你好\"\n",
    "]\n",
    "# 中文进行特征抽取，整句话会被认为一个词，因为中文词之间没有空格\n",
    "transfer = CountVectorizer()\n",
    "data_new = transfer.fit_transform(data)\n",
    "data_new.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 3 1]\n",
      " [1 1 0]] ['你也好', '你好', '背景']\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "  \"你好 你好 你好 啊 背景\",\n",
    "  \"你也好 你好\"\n",
    "]\n",
    "# 手动进行分词\n",
    "# 单个字不进行统计\n",
    "transfer = CountVectorizer()\n",
    "data_new = transfer.fit_transform(data)\n",
    "print(data_new.toarray(), transfer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 中文文本特征抽取 自动分词 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用jieba进行分词处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "安装jieba库：\n",
    "```\n",
    "pip install -i https://pypi.tuna.tsinghua.edu.cn/simple jieba\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "jieba.cut()\n",
    "# 返回词语组成的生成器\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Tokenizer.cut at 0x000001CF3F8EA880>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\cw\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.869 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我 爱 北京 天安门\n"
     ]
    }
   ],
   "source": [
    "text = \"我爱北京天安门\"\n",
    "a = jieba.cut(text)\n",
    "print(a)\n",
    "a = \" \".join(list(a)) # 强转成列表，进行字符串的拼接\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['一种 还是 一种 今天 很 残酷 ， 明天 更 残酷 ， 后天 很 美好 ， 但 绝对 大部分 是 死 在 明天 晚上 ， 所以 每个 人 不要 放弃 今天 。', '我们 看到 的 从 很 远 星系 来 的 光是在 几百万年 之前 发出 的 ， 这样 当 我们 看到 宇宙 时 ， 我们 是 在 看 它 的 过去 。', '如果 只用 一种 方式 了解 某样 事物 ， 你 就 不会 真正 了解 它 。 了解 事物 真正 含义 的 秘密 取决于 如何 将 其 与 我们 所 了解 的 事物 相 联系 。']\n",
      "['一种', '不会', '不要', '之前', '了解', '事物', '今天', '光是在', '几百万年', '发出', '取决于', '只用', '后天', '含义', '大部分', '如何', '如果', '宇宙', '我们', '所以', '放弃', '方式', '明天', '星系', '晚上', '某样', '残酷', '每个', '看到', '真正', '秘密', '绝对', '美好', '联系', '过去', '还是', '这样']\n",
      "[[2 0 1 0 0 0 2 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 2 0 1 0 2 1 0 0 0 1 1 0 0 1\n",
      "  0]\n",
      " [0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 3 0 0 0 0 1 0 0 0 0 2 0 0 0 0 0 1 0\n",
      "  1]\n",
      " [1 1 0 0 4 3 0 0 0 0 1 1 0 1 0 1 1 0 1 0 0 1 0 0 0 1 0 0 0 2 1 0 0 1 0 0\n",
      "  0]]\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "  \"一种还是一种今天很残酷，明天更残酷，后天很美好，但绝对大部分是死在明天晚上，所以每个人不要放弃今天。\",\n",
    "  \"我们看到的从很远星系来的光是在几百万年之前发出的，这样当我们看到宇宙时，我们是在看它的过去。\",\n",
    "  \"如果只用一种方式了解某样事物，你就不会真正了解它。了解事物真正含义的秘密取决于如何将其与我们所了解的事物相联系。\"\n",
    "]\n",
    "# 分词\n",
    "new_data = []\n",
    "for i in data:\n",
    "  new_text = \" \".join(list(jieba.cut(i)))\n",
    "  new_data.append(new_text)\n",
    "print(new_data)\n",
    "# 抽取特征值\n",
    "transfer = CountVectorizer()\n",
    "new_data2 = transfer.fit_transform(new_data)\n",
    "print(transfer.get_feature_names())\n",
    "print(new_data2.toarray()) # sparse 数组转成二维数组"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文本特征抽取 TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF的主要思想是：如果某个词或短语在一篇文章中出现的概率高，并且在其他文章中很少出现，则认为此词或者短语具有很好的类别区分能力，适合用来分类。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF作用：用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF：分类机器学习算法进行文章分类中前期数据处理方式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 公式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF -- 词频（term frequency，tf）指的是某一个给定的词语在该文件中出现的频率\n",
    "$$tf_{i,j} = \\frac{第i篇文章j词语出现的次数}{第i篇文章总词数}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IDF -- 逆向文档频率（inverse document frequency，idf）是一个词语普遍重要性的度量。某一特定词语的idf，可以由总文件数目除以包含该词语之文件的数目，再将得到的商取以10为底的对数得到\n",
    "$$idf = \\log_{10}{\\frac{总文章数目}{包含该词语的文章数目}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$tfidf_{i,j} = tf_{i,j} \\times idf$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "sklearn.feature_extraction.text.TfidfVectorizer(stop_words=[])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "TfidfVectorizer.fit_transform(X) # X: 文本或包含文本字符串的可迭代对象  返回值：词的权重矩阵\n",
    "TfidfVectorizer.inverse_transform(X) # X：array数组或sparse矩阵  返回值：转换之前的数据格式\n",
    "TfidfVectorizer.get_feature_names() # 返回值：单词列表\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['一种 还是 一种 今天 很 残酷 ， 明天 更 残酷 ， 后天 很 美好 ， 但 绝对 大部分 是 死 在 明天 晚上 ， 所以 每个 人 不要 放弃 今天 。', '我们 看到 的 从 很 远 星系 来 的 光是在 几百万年 之前 发出 的 ， 这样 当 我们 看到 宇宙 时 ， 我们 是 在 看 它 的 过去 。', '如果 只用 一种 方式 了解 某样 事物 ， 你 就 不会 真正 了解 它 。 了解 事物 真正 含义 的 秘密 取决于 如何 将 其 与 我们 所 了解 的 事物 相 联系 。']\n",
      "['一种', '不会', '不要', '之前', '了解', '事物', '今天', '光是在', '几百万年', '发出', '取决于', '只用', '后天', '含义', '大部分', '如何', '如果', '宇宙', '我们', '所以', '放弃', '方式', '明天', '星系', '晚上', '某样', '残酷', '每个', '看到', '真正', '秘密', '绝对', '美好', '联系', '过去', '还是', '这样']\n",
      "[[0.30847454 0.         0.20280347 0.         0.         0.\n",
      "  0.40560694 0.         0.         0.         0.         0.\n",
      "  0.20280347 0.         0.20280347 0.         0.         0.\n",
      "  0.         0.20280347 0.20280347 0.         0.40560694 0.\n",
      "  0.20280347 0.         0.40560694 0.20280347 0.         0.\n",
      "  0.         0.20280347 0.20280347 0.         0.         0.20280347\n",
      "  0.        ]\n",
      " [0.         0.         0.         0.2410822  0.         0.\n",
      "  0.         0.2410822  0.2410822  0.2410822  0.         0.\n",
      "  0.         0.         0.         0.         0.         0.2410822\n",
      "  0.55004769 0.         0.         0.         0.         0.2410822\n",
      "  0.         0.         0.         0.         0.48216441 0.\n",
      "  0.         0.         0.         0.         0.2410822  0.\n",
      "  0.2410822 ]\n",
      " [0.12001469 0.15780489 0.         0.         0.63121956 0.47341467\n",
      "  0.         0.         0.         0.         0.15780489 0.15780489\n",
      "  0.         0.15780489 0.         0.15780489 0.15780489 0.\n",
      "  0.12001469 0.         0.         0.15780489 0.         0.\n",
      "  0.         0.15780489 0.         0.         0.         0.31560978\n",
      "  0.15780489 0.         0.         0.15780489 0.         0.\n",
      "  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "  \"一种还是一种今天很残酷，明天更残酷，后天很美好，但绝对大部分是死在明天晚上，所以每个人不要放弃今天。\",\n",
    "  \"我们看到的从很远星系来的光是在几百万年之前发出的，这样当我们看到宇宙时，我们是在看它的过去。\",\n",
    "  \"如果只用一种方式了解某样事物，你就不会真正了解它。了解事物真正含义的秘密取决于如何将其与我们所了解的事物相联系。\"\n",
    "]\n",
    "# 分词\n",
    "new_data = []\n",
    "for i in data:\n",
    "  new_text = \" \".join(list(jieba.cut(i)))\n",
    "  new_data.append(new_text)\n",
    "print(new_data)\n",
    "# 抽取特征值\n",
    "transfer = TfidfVectorizer()\n",
    "new_data2 = transfer.fit_transform(new_data)\n",
    "print(transfer.get_feature_names())\n",
    "print(new_data2.toarray()) # sparse 数组转成二维数组\n",
    "# 数值越大在对应的文章中越重要，越具有分类意义"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "00e0042e4c3c50b48daa1eee0ce7eca131318d2434978781c45622db333e467e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
